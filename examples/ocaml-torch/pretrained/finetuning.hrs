let num_classes = 512 in
let image_height = 326 in (* TODO *)
let image_width = 437 in (* TODO *)
let image_dim = [3, image_height, image_width] in

(* Precompute the last layer of the pre-trained model on the whole dataset. *)
let precompute_activations {ntrain : Nat} {ntest : Nat} (model_path : String) (dataset0 : Dataset ntrain ntest image_dim []) =
  let dataset1 =
    let frozen_vs = VarStore.create #frozen true #name "rn" #device Device.cpu () in
    let pretrained_model =
      TorchVision.Resnet.resnet18 {4 :: image_dim} #num_classes num_classes frozen_vs
    in
    print_string "Loading weights from";
    print_string (lift_string model_path);
    Serialize.load_multi_ #filename model_path
      #named_tensors (VarStore.all_vars {[13]} frozen_vs); (* TODO *)
    print_string "Precomputing activations, this can take a minute...";
    DatasetHelper.map _ _ _ _ {[num_classes]} {[] as List Nat} #batch_size 4
      ( fun(batch_images : Tensor (4 :: image_dim)) ->
        fun(batch_labels : Tensor [4]) ->
          let activations =
            Layer.forward_ pretrained_model #is_training false batch_images
          in
          (Tensor.copy activations, batch_labels)
      )
      Device.cpu
      dataset0
  in
  DatasetHelper.print_summary dataset1;
  dataset1
in

let batch_size = 8 in
let classes = ["ants", "bees"] in
let dataset_dir = "path/to/dataset/" in
let model_path = "path/to/model" in

let dataset =
  TorchVision.Imagenet.load_dataset
    {306} {407} {image_dim} {[] as List Nat} (* TODO *)
    #dir dataset_dir #classes classes
    ()
  in
  DatasetHelper.print_summary dataset;
  let dataset = precompute_activations model_path dataset in
  let train_vs = VarStore.create #frozen false #name "rn-vs" #device Device.cpu () in
  let model (xs : Tensor [batch_size, num_classes]) =
    Layer.forward
      ( Layer.linear {[batch_size]} #input_dim num_classes #output_dim (List.length classes)
          train_vs
          #use_bias true
          Layer.Activation.none
      )
      xs
  in
  let sgd = Optimizer.sgd train_vs #learning_rate 0.001 #momentum 0.9 in
  List.iter (fun(epoch_idx : Int) ->
    let sum_loss = Tensor.f 0.0 in
    DatasetHelper.iter
      #batch_size batch_size
      ( fun(batch_images : Tensor [batch_size, num_classes]) ->
        fun(batch_labels : Tensor [batch_size]) ->
          let predicted = model batch_images in
          (* Compute the cross-entropy loss. *)
          let loss =
            Tensor.cross_entropy_for_logits {batch_size} {2}
              predicted
              #targets batch_labels
          in
          (let open Tensor in sum_loss += loss);
          Optimizer.backward_step #clip_grad Optimizer.ClipGrad.none sgd #loss loss
      )
      Device.cpu
      dataset;
    (* Compute the validation error. *)
    let test_accuracy =
      DatasetHelper.batch_accuracy {2} #batch_size batch_size
        (* `test *)
        #predict model
        Device.cpu
        dataset
    in
    print_string "train loss:";
    print_float
      (Tensor.float_value sum_loss /
        float (DatasetHelper.batches_per_epoch #batch_size batch_size dataset));
    print_string "test accuracy:";
    print_float test_accuracy
  ) (range 1 20)
